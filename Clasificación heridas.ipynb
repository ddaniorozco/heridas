{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ImagenesAProcesar-20200727T214422Z-001.zip',\n",
       " 'Proyecto CNN Heridas.odp',\n",
       " 'Venosas',\n",
       " 'my_model.h5',\n",
       " 'procesar',\n",
       " 'Pioderma Gangrenoso',\n",
       " 'Heridas.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'Arteriales',\n",
       " 'MARTORELL',\n",
       " 'Clasificación heridas.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir ('../Heridas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "25\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('procesar/originales/train/lpp')))\n",
    "print(len(os.listdir('procesar/originales/train/pie')))\n",
    "print(len(os.listdir('procesar/originales/train/vasculares')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "275\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('procesar/originales/train/lpp')))\n",
    "print(len(os.listdir('procesar/originales/train/pie')))\n",
    "print(len(os.listdir('procesar/originales/train/vasculares')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('procesar/originales/val/lpp')))\n",
    "print(len(os.listdir('procesar/originales/val/pie')))\n",
    "print(len(os.listdir('procesar/originales/val/vasculares')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un directorio para las categorias que hago augmentation\n",
    "\n",
    "\n",
    "categorias = ['lpp','pie','vasculares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 1 classes.\n",
      "Found 25 images belonging to 1 classes.\n",
      "Found 42 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "for categoria in categorias:\n",
    "    \n",
    "    \n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    img_class = categoria\n",
    "\n",
    "    img_list = os.listdir('procesar/originales/train/' + img_class)\n",
    "\n",
    "    for fname in img_list:\n",
    "            src = os.path.join('procesar/originales/train/' + img_class, fname)\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "    path = aug_dir\n",
    "    save_path = 'procesar/originales/train/' + img_class\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                           save_to_dir=save_path,\n",
    "                                           save_format='jpg',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "    num_aug_images_wanted = 500 \n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "    for i in range(0,num_batches):\n",
    "        imgs, labels = next(aug_datagen)\n",
    "        \n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'procesar/originales/train'\n",
    "val_path = 'procesar/originales/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 946\n",
    "val_samples = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = np.ceil (train_samples / train_batch_size)\n",
    "val_steps = np.ceil (val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "    tensorflow.keras.applications.mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 946 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batches = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net = tensorflow.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (mobile_net.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura del modelo\n",
    "\n",
    "# Excluir las ultimas 5 capas del modelo\n",
    "# Incluye hasta global_average_pooling2d\n",
    "\n",
    "x = mobile_net.layers [-6].output\n",
    "\n",
    "# Crear una nueva capa densa para predicciones. 3 categorías\n",
    "\n",
    "x = Dropout (0.25)(x) # Dropout reduce el overfitting al train\n",
    "\n",
    "predictions = Dense (3, activation = 'softmax')(x)\n",
    "\n",
    "model = Model (inputs = mobile_net.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 3,210,051\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elección de capas a ser entrenadas, las ultimas 23\n",
    "\n",
    "# Las demas no se entrenan\n",
    "\n",
    "for layer in mobile_net.layers [:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "    \n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lpp': 0, 'pie': 1, 'vasculares': 2}\n"
     ]
    }
   ],
   "source": [
    "print(valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 2.0, # lpp\n",
    "    1: 1.0, # pie\n",
    "    2: 1.0, # vasculares    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.9361 - categorical_accuracy: 0.8615\n",
      "Epoch 00001: val_loss improved from -inf to 36.53821, saving model to model.h5\n",
      "95/95 [==============================] - 51s 535ms/step - loss: 0.9361 - categorical_accuracy: 0.8615 - val_loss: 36.5382 - val_categorical_accuracy: 0.4444\n",
      "Epoch 2/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.9101\n",
      "Epoch 00002: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 50s 527ms/step - loss: 0.4705 - categorical_accuracy: 0.9101 - val_loss: 5.1268 - val_categorical_accuracy: 0.6667\n",
      "Epoch 3/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.2233 - categorical_accuracy: 0.9514\n",
      "Epoch 00003: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "95/95 [==============================] - 50s 527ms/step - loss: 0.2233 - categorical_accuracy: 0.9514 - val_loss: 7.0823 - val_categorical_accuracy: 0.7222\n",
      "Epoch 4/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0922 - categorical_accuracy: 0.9757\n",
      "Epoch 00004: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 532ms/step - loss: 0.0922 - categorical_accuracy: 0.9757 - val_loss: 6.0956 - val_categorical_accuracy: 0.6111\n",
      "Epoch 5/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0825 - categorical_accuracy: 0.9841\n",
      "Epoch 00005: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "95/95 [==============================] - 50s 531ms/step - loss: 0.0825 - categorical_accuracy: 0.9841 - val_loss: 0.5912 - val_categorical_accuracy: 0.9444\n",
      "Epoch 6/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0835 - categorical_accuracy: 0.9873\n",
      "Epoch 00006: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 533ms/step - loss: 0.0835 - categorical_accuracy: 0.9873 - val_loss: 0.5506 - val_categorical_accuracy: 0.8889\n",
      "Epoch 7/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0147 - categorical_accuracy: 0.9968\n",
      "Epoch 00007: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "95/95 [==============================] - 50s 531ms/step - loss: 0.0147 - categorical_accuracy: 0.9968 - val_loss: 0.5101 - val_categorical_accuracy: 0.8889\n",
      "Epoch 8/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0132 - categorical_accuracy: 0.9958\n",
      "Epoch 00008: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 533ms/step - loss: 0.0132 - categorical_accuracy: 0.9958 - val_loss: 0.7330 - val_categorical_accuracy: 0.9444\n",
      "Epoch 9/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 0.9979\n",
      "Epoch 00009: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "95/95 [==============================] - 50s 530ms/step - loss: 0.0054 - categorical_accuracy: 0.9979 - val_loss: 0.6094 - val_categorical_accuracy: 0.9444\n",
      "Epoch 10/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0113 - categorical_accuracy: 0.9968\n",
      "Epoch 00010: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 532ms/step - loss: 0.0113 - categorical_accuracy: 0.9968 - val_loss: 0.6839 - val_categorical_accuracy: 0.9444\n",
      "Epoch 11/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0039 - categorical_accuracy: 0.9989\n",
      "Epoch 00011: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0039 - categorical_accuracy: 0.9989 - val_loss: 0.7131 - val_categorical_accuracy: 0.9444\n",
      "Epoch 12/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 0.9979\n",
      "Epoch 00012: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 544ms/step - loss: 0.0078 - categorical_accuracy: 0.9979 - val_loss: 0.6793 - val_categorical_accuracy: 0.9444\n",
      "Epoch 13/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0250 - categorical_accuracy: 0.9937\n",
      "Epoch 00013: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "95/95 [==============================] - 52s 544ms/step - loss: 0.0250 - categorical_accuracy: 0.9937 - val_loss: 0.5982 - val_categorical_accuracy: 0.9444\n",
      "Epoch 14/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0113 - categorical_accuracy: 0.9968\n",
      "Epoch 00014: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 540ms/step - loss: 0.0113 - categorical_accuracy: 0.9968 - val_loss: 0.6187 - val_categorical_accuracy: 0.9444\n",
      "Epoch 15/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "95/95 [==============================] - 52s 549ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.6121 - val_categorical_accuracy: 0.9444\n",
      "Epoch 16/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0087 - categorical_accuracy: 0.9979\n",
      "Epoch 00016: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 551ms/step - loss: 0.0087 - categorical_accuracy: 0.9979 - val_loss: 0.6232 - val_categorical_accuracy: 0.9444\n",
      "Epoch 17/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0098 - categorical_accuracy: 0.9968\n",
      "Epoch 00017: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "95/95 [==============================] - 52s 544ms/step - loss: 0.0098 - categorical_accuracy: 0.9968 - val_loss: 0.6252 - val_categorical_accuracy: 0.9444\n",
      "Epoch 18/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 0.9968\n",
      "Epoch 00018: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 546ms/step - loss: 0.0191 - categorical_accuracy: 0.9968 - val_loss: 0.6226 - val_categorical_accuracy: 0.9444\n",
      "Epoch 19/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0574 - categorical_accuracy: 0.9968\n",
      "Epoch 00019: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "95/95 [==============================] - 54s 568ms/step - loss: 0.0574 - categorical_accuracy: 0.9968 - val_loss: 0.6295 - val_categorical_accuracy: 0.9444\n",
      "Epoch 20/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 548ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.6254 - val_categorical_accuracy: 0.9444\n",
      "Epoch 21/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0085 - categorical_accuracy: 0.9979\n",
      "Epoch 00021: val_loss did not improve from 36.53821\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0085 - categorical_accuracy: 0.9979 - val_loss: 0.6346 - val_categorical_accuracy: 0.9444\n",
      "Epoch 22/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9958\n",
      "Epoch 00022: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0569 - categorical_accuracy: 0.9958 - val_loss: 0.6423 - val_categorical_accuracy: 0.9444\n",
      "Epoch 23/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0051 - categorical_accuracy: 0.9989\n",
      "Epoch 00023: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0051 - categorical_accuracy: 0.9989 - val_loss: 0.6407 - val_categorical_accuracy: 0.9444\n",
      "Epoch 24/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0070 - categorical_accuracy: 0.9979\n",
      "Epoch 00024: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 540ms/step - loss: 0.0070 - categorical_accuracy: 0.9979 - val_loss: 0.6497 - val_categorical_accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0036 - categorical_accuracy: 1.0000\n",
      "Epoch 00025: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0036 - categorical_accuracy: 1.0000 - val_loss: 0.6409 - val_categorical_accuracy: 0.9444\n",
      "Epoch 26/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0168 - categorical_accuracy: 0.9968\n",
      "Epoch 00026: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0168 - categorical_accuracy: 0.9968 - val_loss: 0.6398 - val_categorical_accuracy: 0.9444\n",
      "Epoch 27/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0038 - categorical_accuracy: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 534ms/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.6313 - val_categorical_accuracy: 0.9444\n",
      "Epoch 28/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 0.9989\n",
      "Epoch 00028: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0048 - categorical_accuracy: 0.9989 - val_loss: 0.6279 - val_categorical_accuracy: 0.9444\n",
      "Epoch 29/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0478 - categorical_accuracy: 0.9979\n",
      "Epoch 00029: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0478 - categorical_accuracy: 0.9979 - val_loss: 0.6129 - val_categorical_accuracy: 0.9444\n",
      "Epoch 30/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0066 - categorical_accuracy: 0.9979\n",
      "Epoch 00030: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0066 - categorical_accuracy: 0.9979 - val_loss: 0.6389 - val_categorical_accuracy: 0.9444\n",
      "Epoch 31/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0177 - categorical_accuracy: 0.9958\n",
      "Epoch 00031: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 534ms/step - loss: 0.0177 - categorical_accuracy: 0.9958 - val_loss: 0.6404 - val_categorical_accuracy: 0.9444\n",
      "Epoch 32/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 1.0000\n",
      "Epoch 00032: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 0.6426 - val_categorical_accuracy: 0.9444\n",
      "Epoch 33/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9989\n",
      "Epoch 00033: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0242 - categorical_accuracy: 0.9989 - val_loss: 0.6338 - val_categorical_accuracy: 0.9444\n",
      "Epoch 34/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0056 - categorical_accuracy: 0.9979\n",
      "Epoch 00034: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0056 - categorical_accuracy: 0.9979 - val_loss: 0.6318 - val_categorical_accuracy: 0.9444\n",
      "Epoch 35/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0068 - categorical_accuracy: 0.9979\n",
      "Epoch 00035: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0068 - categorical_accuracy: 0.9979 - val_loss: 0.6313 - val_categorical_accuracy: 0.9444\n",
      "Epoch 36/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0112 - categorical_accuracy: 0.9968\n",
      "Epoch 00036: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0112 - categorical_accuracy: 0.9968 - val_loss: 0.6315 - val_categorical_accuracy: 0.9444\n",
      "Epoch 37/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0063 - categorical_accuracy: 0.9989\n",
      "Epoch 00037: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0063 - categorical_accuracy: 0.9989 - val_loss: 0.6350 - val_categorical_accuracy: 0.9444\n",
      "Epoch 38/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0555 - categorical_accuracy: 0.9968\n",
      "Epoch 00038: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0555 - categorical_accuracy: 0.9968 - val_loss: 0.6271 - val_categorical_accuracy: 0.9444\n",
      "Epoch 39/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.6313 - val_categorical_accuracy: 0.9444\n",
      "Epoch 40/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.6374 - val_categorical_accuracy: 0.9444\n",
      "Epoch 41/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0040 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 540ms/step - loss: 0.0040 - categorical_accuracy: 1.0000 - val_loss: 0.6280 - val_categorical_accuracy: 0.9444\n",
      "Epoch 42/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0032 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 542ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.6364 - val_categorical_accuracy: 0.9444\n",
      "Epoch 43/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0080 - categorical_accuracy: 0.9979\n",
      "Epoch 00043: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0080 - categorical_accuracy: 0.9979 - val_loss: 0.6231 - val_categorical_accuracy: 0.9444\n",
      "Epoch 44/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0682 - categorical_accuracy: 0.9979\n",
      "Epoch 00044: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0682 - categorical_accuracy: 0.9979 - val_loss: 0.6220 - val_categorical_accuracy: 0.9444\n",
      "Epoch 45/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0079 - categorical_accuracy: 0.9989\n",
      "Epoch 00045: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0079 - categorical_accuracy: 0.9989 - val_loss: 0.6134 - val_categorical_accuracy: 0.9444\n",
      "Epoch 46/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0073 - categorical_accuracy: 0.9968\n",
      "Epoch 00046: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0073 - categorical_accuracy: 0.9968 - val_loss: 0.6203 - val_categorical_accuracy: 0.9444\n",
      "Epoch 47/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0139 - categorical_accuracy: 0.9968\n",
      "Epoch 00047: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0139 - categorical_accuracy: 0.9968 - val_loss: 0.6195 - val_categorical_accuracy: 0.9444\n",
      "Epoch 48/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0138 - categorical_accuracy: 0.9968\n",
      "Epoch 00048: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0138 - categorical_accuracy: 0.9968 - val_loss: 0.6321 - val_categorical_accuracy: 0.9444\n",
      "Epoch 49/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0387 - categorical_accuracy: 0.9958\n",
      "Epoch 00049: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0387 - categorical_accuracy: 0.9958 - val_loss: 0.6317 - val_categorical_accuracy: 0.9444\n",
      "Epoch 50/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 542ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.6231 - val_categorical_accuracy: 0.9444\n",
      "Epoch 51/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 0.0194 - categorical_accuracy: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 549ms/step - loss: 0.0194 - categorical_accuracy: 0.9937 - val_loss: 0.6284 - val_categorical_accuracy: 0.9444\n",
      "Epoch 52/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0126 - categorical_accuracy: 0.9958\n",
      "Epoch 00052: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 535ms/step - loss: 0.0126 - categorical_accuracy: 0.9958 - val_loss: 0.6491 - val_categorical_accuracy: 0.9444\n",
      "Epoch 53/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0037 - categorical_accuracy: 0.9989\n",
      "Epoch 00053: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0037 - categorical_accuracy: 0.9989 - val_loss: 0.6368 - val_categorical_accuracy: 0.9444\n",
      "Epoch 54/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0759 - categorical_accuracy: 0.9937\n",
      "Epoch 00054: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0759 - categorical_accuracy: 0.9937 - val_loss: 0.6312 - val_categorical_accuracy: 0.9444\n",
      "Epoch 55/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0034 - categorical_accuracy: 0.9989\n",
      "Epoch 00055: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0034 - categorical_accuracy: 0.9989 - val_loss: 0.6220 - val_categorical_accuracy: 0.9444\n",
      "Epoch 56/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0119 - categorical_accuracy: 0.9968\n",
      "Epoch 00056: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0119 - categorical_accuracy: 0.9968 - val_loss: 0.6340 - val_categorical_accuracy: 0.9444\n",
      "Epoch 57/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.6252 - val_categorical_accuracy: 0.9444\n",
      "Epoch 58/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0203 - categorical_accuracy: 0.9989\n",
      "Epoch 00058: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0203 - categorical_accuracy: 0.9989 - val_loss: 0.6125 - val_categorical_accuracy: 0.9444\n",
      "Epoch 59/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 542ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.6230 - val_categorical_accuracy: 0.9444\n",
      "Epoch 60/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0065 - categorical_accuracy: 0.9979\n",
      "Epoch 00060: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0065 - categorical_accuracy: 0.9979 - val_loss: 0.6244 - val_categorical_accuracy: 0.9444\n",
      "Epoch 61/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1010e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 53s 553ms/step - loss: 8.1010e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6101 - val_categorical_accuracy: 0.9444\n",
      "Epoch 62/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0126 - categorical_accuracy: 0.9989\n",
      "Epoch 00062: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0126 - categorical_accuracy: 0.9989 - val_loss: 0.6020 - val_categorical_accuracy: 0.9444\n",
      "Epoch 63/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 0.9979\n",
      "Epoch 00063: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0054 - categorical_accuracy: 0.9979 - val_loss: 0.5982 - val_categorical_accuracy: 0.9444\n",
      "Epoch 64/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0115 - categorical_accuracy: 0.9979\n",
      "Epoch 00064: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 542ms/step - loss: 0.0115 - categorical_accuracy: 0.9979 - val_loss: 0.6152 - val_categorical_accuracy: 0.9444\n",
      "Epoch 65/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0060 - categorical_accuracy: 0.9989\n",
      "Epoch 00065: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0060 - categorical_accuracy: 0.9989 - val_loss: 0.5980 - val_categorical_accuracy: 0.9444\n",
      "Epoch 66/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0065 - categorical_accuracy: 0.9979\n",
      "Epoch 00066: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0065 - categorical_accuracy: 0.9979 - val_loss: 0.5990 - val_categorical_accuracy: 0.9444\n",
      "Epoch 67/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0485 - categorical_accuracy: 0.9937\n",
      "Epoch 00067: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 540ms/step - loss: 0.0485 - categorical_accuracy: 0.9937 - val_loss: 0.5976 - val_categorical_accuracy: 0.9444\n",
      "Epoch 68/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0032 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.6117 - val_categorical_accuracy: 0.9444\n",
      "Epoch 69/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.6018 - val_categorical_accuracy: 0.9444\n",
      "Epoch 70/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0031 - categorical_accuracy: 0.9989\n",
      "Epoch 00070: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 536ms/step - loss: 0.0031 - categorical_accuracy: 0.9989 - val_loss: 0.6087 - val_categorical_accuracy: 0.9444\n",
      "Epoch 71/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0082 - categorical_accuracy: 0.9979\n",
      "Epoch 00071: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 537ms/step - loss: 0.0082 - categorical_accuracy: 0.9979 - val_loss: 0.6246 - val_categorical_accuracy: 0.9444\n",
      "Epoch 72/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0030 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 539ms/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 0.6162 - val_categorical_accuracy: 0.9444\n",
      "Epoch 73/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0057 - categorical_accuracy: 0.9979\n",
      "Epoch 00073: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 52s 548ms/step - loss: 0.0057 - categorical_accuracy: 0.9979 - val_loss: 0.6050 - val_categorical_accuracy: 0.9444\n",
      "Epoch 74/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0241 - categorical_accuracy: 0.9926\n",
      "Epoch 00074: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0241 - categorical_accuracy: 0.9926 - val_loss: 0.6060 - val_categorical_accuracy: 0.9444\n",
      "Epoch 75/75\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.0101 - categorical_accuracy: 0.9979\n",
      "Epoch 00075: val_loss did not improve from 36.53821\n",
      "95/95 [==============================] - 51s 538ms/step - loss: 0.0101 - categorical_accuracy: 0.9979 - val_loss: 0.5993 - val_categorical_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = \"training_1/cp.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(train_batches, steps_per_epoch=train_steps, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=75, verbose=1,\n",
    "                   callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 1,860,099\n",
      "Non-trainable params: 1,371,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "heridas_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "heridas_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies = {\n",
    "#    'valid_accuracy': ValidAccuracy\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.figure()\n",
    "\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'b', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.grid ()\n",
    "plt.figure()\n",
    "\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lpp': 0, 'pie': 1, 'vasculares': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_batches, steps= (val_samples), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "   \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Matriz de confusión')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Obtenidos')\n",
    "    plt.xlabel('Predichos')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[3 1 0]\n",
      " [0 6 0]\n",
      " [0 0 8]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['lpp', 'pie', 'vasculares']\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Matriz de confusión')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "y_true = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lpp       1.00      0.75      0.86         4\n",
      "         pie       0.86      1.00      0.92         6\n",
      "  vasculares       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.95      0.92      0.93        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.predict of <tensorflow.python.keras.engine.functional.Functional object at 0x7f2b7058e748>>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.predict of <tensorflow.python.keras.engine.functional.Functional object at 0x7f2b317224a8>>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heridas_model.predict ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-1b822c486a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/pred/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-692b0bfd4d9a>\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Extracting the file name of the image from Class Label folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mr'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Reading the image (OpenCV)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Resize the image, Some images are different sizes. (Resizing is very Important)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "pred_images = get_images('../input/pred/')\n",
    "pred_images = np.array(pred_images)\n",
    "pred_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'procesar/originales/train/vasculares/_3_1447968.jpg'\n",
    "new_image = load_image (img_path)\n",
    "\n",
    "prediccion = heridas_model.predict (new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path = 'procesar/originales/prueba/'\n",
    "#new_image = load_image (img_path)\n",
    "\n",
    "#prediccion = heridas_model.predict (new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad que sea LPP, Pie diabetico o Ulcera vascular:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0094951e-15, 1.4919672e-14, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificacion_heridas (prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Iterator.next of <tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x7f2b901e86d8>>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches.next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_batches.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[-0.8666667 , -0.8666667 , -0.9607843 ],\n",
       "          [-0.8352941 , -0.8509804 , -0.94509804],\n",
       "          [-0.81960785, -0.8352941 , -0.92941177],\n",
       "          ...,\n",
       "          [-0.8980392 , -0.92941177, -0.9529412 ],\n",
       "          [-0.92156863, -0.9529412 , -0.9764706 ],\n",
       "          [-0.9372549 , -0.96862745, -0.9764706 ]],\n",
       " \n",
       "         [[-0.8666667 , -0.8666667 , -0.94509804],\n",
       "          [-0.8509804 , -0.8509804 , -0.92941177],\n",
       "          [-0.81960785, -0.84313726, -0.9137255 ],\n",
       "          ...,\n",
       "          [-0.8980392 , -0.92941177, -0.9529412 ],\n",
       "          [-0.92156863, -0.9529412 , -0.9764706 ],\n",
       "          [-0.9372549 , -0.96862745, -0.9764706 ]],\n",
       " \n",
       "         [[-0.8666667 , -0.8666667 , -0.92941177],\n",
       "          [-0.8509804 , -0.8509804 , -0.9137255 ],\n",
       "          [-0.81960785, -0.84313726, -0.8980392 ],\n",
       "          ...,\n",
       "          [-0.8980392 , -0.92941177, -0.9529412 ],\n",
       "          [-0.92156863, -0.9529412 , -0.9764706 ],\n",
       "          [-0.9372549 , -0.96862745, -0.9764706 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.05882359, -0.4823529 , -1.        ],\n",
       "          [ 0.05882359, -0.4823529 , -1.        ],\n",
       "          [ 0.06666672, -0.47450978, -1.        ],\n",
       "          ...,\n",
       "          [-0.24705881, -0.7411765 , -1.        ],\n",
       "          [-0.24705881, -0.7411765 , -1.        ],\n",
       "          [-0.23921567, -0.7411765 , -1.        ]],\n",
       " \n",
       "         [[ 0.04313731, -0.4980392 , -1.        ],\n",
       "          [ 0.05098045, -0.49019605, -1.        ],\n",
       "          [ 0.05882359, -0.4823529 , -1.        ],\n",
       "          ...,\n",
       "          [-0.23921567, -0.73333335, -0.99215686],\n",
       "          [-0.23921567, -0.73333335, -0.99215686],\n",
       "          [-0.23921567, -0.73333335, -0.99215686]],\n",
       " \n",
       "         [[ 0.03529418, -0.5058824 , -1.        ],\n",
       "          [ 0.04313731, -0.4980392 , -1.        ],\n",
       "          [ 0.05098045, -0.49019605, -1.        ],\n",
       "          ...,\n",
       "          [-0.26274508, -0.73333335, -1.        ],\n",
       "          [-0.26274508, -0.73333335, -1.        ],\n",
       "          [-0.26274508, -0.73333335, -1.        ]]],\n",
       " \n",
       " \n",
       "        [[[-0.5058824 ,  0.04313731,  0.5058824 ],\n",
       "          [-0.45098037,  0.09803927,  0.56078434],\n",
       "          [-0.44313723,  0.10588241,  0.5686275 ],\n",
       "          ...,\n",
       "          [ 0.77254903,  0.6392157 ,  0.5764706 ],\n",
       "          [ 0.7647059 ,  0.6313726 ,  0.5686275 ],\n",
       "          [ 0.7647059 ,  0.6313726 ,  0.5686275 ]],\n",
       " \n",
       "         [[-0.38823527,  0.16078436,  0.62352943],\n",
       "          [-0.32549018,  0.22352946,  0.6862745 ],\n",
       "          [-0.4352941 ,  0.11372554,  0.5764706 ],\n",
       "          ...,\n",
       "          [ 0.73333335,  0.6       ,  0.5372549 ],\n",
       "          [ 0.73333335,  0.6       ,  0.5372549 ],\n",
       "          [ 0.7254902 ,  0.5921569 ,  0.5294118 ]],\n",
       " \n",
       "         [[-0.67058825, -0.12156862,  0.3411765 ],\n",
       "          [-0.41176468,  0.13725495,  0.6       ],\n",
       "          [-0.32549018,  0.23921573,  0.69411767],\n",
       "          ...,\n",
       "          [ 0.8039216 ,  0.67058825,  0.5921569 ],\n",
       "          [ 0.8039216 ,  0.67058825,  0.5921569 ],\n",
       "          [ 0.8039216 ,  0.67058825,  0.5921569 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.73333335, -0.64705884, -0.70980394],\n",
       "          [-0.73333335, -0.64705884, -0.70980394],\n",
       "          [-0.73333335, -0.64705884, -0.70980394],\n",
       "          ...,\n",
       "          [-0.12941176,  0.12941182,  0.07450986],\n",
       "          [-0.1607843 ,  0.09803927,  0.04313731],\n",
       "          [-0.11372548,  0.14509809,  0.09019613]],\n",
       " \n",
       "         [[-0.6862745 , -0.58431375, -0.6627451 ],\n",
       "          [-0.654902  , -0.5529412 , -0.6313726 ],\n",
       "          [-0.6156863 , -0.5137255 , -0.5921569 ],\n",
       "          ...,\n",
       "          [-0.12941176,  0.12941182,  0.07450986],\n",
       "          [-0.1607843 ,  0.09803927,  0.04313731],\n",
       "          [-0.11372548,  0.14509809,  0.09019613]],\n",
       " \n",
       "         [[-0.21568626, -0.11372548, -0.19215685],\n",
       "          [-0.19999999, -0.09803921, -0.17647058],\n",
       "          [-0.1607843 , -0.05882353, -0.1372549 ],\n",
       "          ...,\n",
       "          [-0.12941176,  0.12941182,  0.07450986],\n",
       "          [-0.1607843 ,  0.09803927,  0.04313731],\n",
       "          [-0.11372548,  0.14509809,  0.09019613]]],\n",
       " \n",
       " \n",
       "        [[[-0.827451  , -0.84313726, -0.81960785],\n",
       "          [-0.81960785, -0.8352941 , -0.8117647 ],\n",
       "          [-0.8039216 , -0.81960785, -0.79607844],\n",
       "          ...,\n",
       "          [-0.8509804 , -0.92156863, -0.88235295],\n",
       "          [-0.8666667 , -0.9137255 , -0.88235295],\n",
       "          [-0.88235295, -0.9372549 , -0.88235295]],\n",
       " \n",
       "         [[-0.81960785, -0.8352941 , -0.8117647 ],\n",
       "          [-0.8117647 , -0.827451  , -0.8039216 ],\n",
       "          [-0.8039216 , -0.81960785, -0.79607844],\n",
       "          ...,\n",
       "          [-0.85882354, -0.92941177, -0.8901961 ],\n",
       "          [-0.88235295, -0.92941177, -0.8980392 ],\n",
       "          [-0.8980392 , -0.9529412 , -0.8980392 ]],\n",
       " \n",
       "         [[-0.8117647 , -0.827451  , -0.8039216 ],\n",
       "          [-0.8117647 , -0.827451  , -0.8039216 ],\n",
       "          [-0.8117647 , -0.827451  , -0.8039216 ],\n",
       "          ...,\n",
       "          [-0.8901961 , -0.9372549 , -0.90588236],\n",
       "          [-0.8980392 , -0.94509804, -0.9137255 ],\n",
       "          [-0.9137255 , -0.9607843 , -0.92941177]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.90588236, -0.9372549 , -0.92941177],\n",
       "          [-0.9137255 , -0.94509804, -0.9372549 ],\n",
       "          [-0.92941177, -0.9607843 , -0.9529412 ],\n",
       "          ...,\n",
       "          [-0.9764706 , -0.99215686, -0.8901961 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ]],\n",
       " \n",
       "         [[-0.92941177, -0.9607843 , -0.9529412 ],\n",
       "          [-0.92941177, -0.9607843 , -0.9529412 ],\n",
       "          [-0.9372549 , -0.96862745, -0.9607843 ],\n",
       "          ...,\n",
       "          [-0.9843137 , -1.        , -0.8980392 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ]],\n",
       " \n",
       "         [[-0.94509804, -0.9764706 , -0.96862745],\n",
       "          [-0.94509804, -0.9764706 , -0.96862745],\n",
       "          [-0.9372549 , -0.96862745, -0.9607843 ],\n",
       "          ...,\n",
       "          [-0.9843137 , -1.        , -0.8980392 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ],\n",
       "          [-0.9843137 , -1.        , -0.8980392 ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 0.78039217,  0.48235297,  0.47450984],\n",
       "          [ 0.77254903,  0.47450984,  0.4666667 ],\n",
       "          [ 0.75686276,  0.45882356,  0.45098042],\n",
       "          ...,\n",
       "          [-0.9843137 , -0.96862745, -1.        ],\n",
       "          [-0.9764706 , -0.9372549 , -0.9843137 ],\n",
       "          [-0.9607843 , -0.90588236, -0.9607843 ]],\n",
       " \n",
       "         [[ 0.7176471 ,  0.41960788,  0.41176474],\n",
       "          [ 0.73333335,  0.43529415,  0.427451  ],\n",
       "          [ 0.75686276,  0.45882356,  0.45098042],\n",
       "          ...,\n",
       "          [-0.9764706 , -0.9607843 , -1.        ],\n",
       "          [-0.9764706 , -0.9372549 , -0.9843137 ],\n",
       "          [-0.96862745, -0.9137255 , -0.96862745]],\n",
       " \n",
       "         [[ 0.7254902 ,  0.427451  ,  0.41960788],\n",
       "          [ 0.73333335,  0.43529415,  0.427451  ],\n",
       "          [ 0.7490196 ,  0.45098042,  0.4431373 ],\n",
       "          ...,\n",
       "          [-0.9529412 , -0.9372549 , -0.9764706 ],\n",
       "          [-0.9764706 , -0.9372549 , -0.9843137 ],\n",
       "          [-0.99215686, -0.9372549 , -0.99215686]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.827451  ,  0.84313726,  0.8039216 ],\n",
       "          [ 0.827451  ,  0.84313726,  0.8039216 ],\n",
       "          [ 0.79607844,  0.8117647 ,  0.77254903],\n",
       "          ...,\n",
       "          [ 0.79607844,  0.32549024,  0.4039216 ],\n",
       "          [ 0.8117647 ,  0.3411765 ,  0.43529415],\n",
       "          [ 0.81960785,  0.34901965,  0.4431373 ]],\n",
       " \n",
       "         [[ 0.84313726,  0.85882354,  0.81960785],\n",
       "          [ 0.79607844,  0.8117647 ,  0.77254903],\n",
       "          [ 0.77254903,  0.7882353 ,  0.7490196 ],\n",
       "          ...,\n",
       "          [ 0.77254903,  0.30196083,  0.3803922 ],\n",
       "          [ 0.78039217,  0.30980396,  0.38823533],\n",
       "          [ 0.78039217,  0.30980396,  0.4039216 ]],\n",
       " \n",
       "         [[ 0.85882354,  0.8745098 ,  0.8352941 ],\n",
       "          [ 0.77254903,  0.7882353 ,  0.7490196 ],\n",
       "          [ 0.75686276,  0.77254903,  0.73333335],\n",
       "          ...,\n",
       "          [ 0.77254903,  0.30196083,  0.3803922 ],\n",
       "          [ 0.7647059 ,  0.2941177 ,  0.37254906],\n",
       "          [ 0.75686276,  0.28627455,  0.36470592]]],\n",
       " \n",
       " \n",
       "        [[[ 0.2941177 ,  0.14509809,  0.01176476],\n",
       "          [ 0.30980396,  0.16078436,  0.02745104],\n",
       "          [ 0.2941177 ,  0.15294123, -0.00392157],\n",
       "          ...,\n",
       "          [-0.73333335, -0.77254903, -0.8039216 ],\n",
       "          [-0.7490196 , -0.7882353 , -0.81960785],\n",
       "          [-0.75686276, -0.79607844, -0.827451  ]],\n",
       " \n",
       "         [[ 0.30980396,  0.16078436,  0.02745104],\n",
       "          [ 0.32549024,  0.17647064,  0.04313731],\n",
       "          [ 0.30980396,  0.1686275 ,  0.01176476],\n",
       "          ...,\n",
       "          [-0.7411765 , -0.78039217, -0.8117647 ],\n",
       "          [-0.7411765 , -0.78039217, -0.8117647 ],\n",
       "          [-0.7411765 , -0.78039217, -0.8117647 ]],\n",
       " \n",
       "         [[ 0.3176471 ,  0.1686275 ,  0.03529418],\n",
       "          [ 0.3411765 ,  0.19215691,  0.05882359],\n",
       "          [ 0.32549024,  0.17647064,  0.04313731],\n",
       "          ...,\n",
       "          [-0.75686276, -0.79607844, -0.827451  ],\n",
       "          [-0.7411765 , -0.78039217, -0.8117647 ],\n",
       "          [-0.73333335, -0.77254903, -0.8039216 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.69411767,  0.5686275 ,  0.45098042],\n",
       "          [ 0.6627451 ,  0.5372549 ,  0.41960788],\n",
       "          [ 0.60784316,  0.48235297,  0.36470592],\n",
       "          ...,\n",
       "          [-0.41176468, -0.69411767, -0.7882353 ],\n",
       "          [-0.3960784 , -0.6784314 , -0.77254903],\n",
       "          [-0.38823527, -0.67058825, -0.7647059 ]],\n",
       " \n",
       "         [[ 0.60784316,  0.48235297,  0.36470592],\n",
       "          [ 0.54509807,  0.41960788,  0.30196083],\n",
       "          [ 0.45098042,  0.32549024,  0.20784318],\n",
       "          ...,\n",
       "          [-0.41960782, -0.7019608 , -0.79607844],\n",
       "          [-0.3960784 , -0.6784314 , -0.77254903],\n",
       "          [-0.38039213, -0.6627451 , -0.75686276]],\n",
       " \n",
       "         [[ 0.4666667 ,  0.3411765 ,  0.22352946],\n",
       "          [ 0.39607847,  0.27058828,  0.15294123],\n",
       "          [ 0.28627455,  0.16078436,  0.04313731],\n",
       "          ...,\n",
       "          [-0.42745095, -0.70980394, -0.8039216 ],\n",
       "          [-0.3960784 , -0.6784314 , -0.77254903],\n",
       "          [-0.372549  , -0.654902  , -0.7490196 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.27058828, -0.21568626, -0.5058824 ],\n",
       "          [ 0.27058828, -0.21568626, -0.5058824 ],\n",
       "          [ 0.24705887, -0.24705881, -0.52156866],\n",
       "          ...,\n",
       "          [ 0.75686276,  0.02745104, -0.11372548],\n",
       "          [ 0.7490196 ,  0.0196079 , -0.12156862],\n",
       "          [ 0.7411765 ,  0.01176476, -0.12941176]],\n",
       " \n",
       "         [[ 0.24705887, -0.23921567, -0.54509807],\n",
       "          [ 0.27058828, -0.21568626, -0.5058824 ],\n",
       "          [ 0.27058828, -0.21568626, -0.5058824 ],\n",
       "          ...,\n",
       "          [ 0.7490196 ,  0.0196079 , -0.12156862],\n",
       "          [ 0.7411765 ,  0.01176476, -0.12941176],\n",
       "          [ 0.73333335,  0.00392163, -0.1372549 ]],\n",
       " \n",
       "         [[ 0.23921573, -0.24705881, -0.5529412 ],\n",
       "          [ 0.27058828, -0.21568626, -0.52156866],\n",
       "          [ 0.2941177 , -0.19215685, -0.4823529 ],\n",
       "          ...,\n",
       "          [ 0.7490196 ,  0.0196079 , -0.12156862],\n",
       "          [ 0.73333335,  0.00392163, -0.1372549 ],\n",
       "          [ 0.7254902 , -0.00392157, -0.14509803]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.7019608 ,  0.4039216 ,  0.254902  ],\n",
       "          [ 0.6862745 ,  0.38823533,  0.23921573],\n",
       "          [ 0.67058825,  0.37254906,  0.22352946],\n",
       "          ...,\n",
       "          [ 0.12941182, -0.2862745 , -0.6       ],\n",
       "          [ 0.12156868, -0.29411763, -0.60784316],\n",
       "          [ 0.10588241, -0.3098039 , -0.62352943]],\n",
       " \n",
       "         [[ 0.69411767,  0.39607847,  0.24705887],\n",
       "          [ 0.67058825,  0.37254906,  0.22352946],\n",
       "          [ 0.6627451 ,  0.3411765 ,  0.20000005],\n",
       "          ...,\n",
       "          [ 0.11372554, -0.30196077, -0.6156863 ],\n",
       "          [ 0.11372554, -0.30196077, -0.6156863 ],\n",
       "          [ 0.12156868, -0.29411763, -0.60784316]],\n",
       " \n",
       "         [[ 0.6784314 ,  0.3803922 ,  0.2313726 ],\n",
       "          [ 0.654902  ,  0.35686278,  0.20784318],\n",
       "          [ 0.6392157 ,  0.3176471 ,  0.17647064],\n",
       "          ...,\n",
       "          [ 0.09803927, -0.31764704, -0.6313726 ],\n",
       "          [ 0.11372554, -0.30196077, -0.6156863 ],\n",
       "          [ 0.13725495, -0.27843136, -0.5921569 ]]]], dtype=float32),\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.07843138, 0.03921569, 0.03137255],\n",
       "         [0.0627451 , 0.02352941, 0.01568628],\n",
       "         [0.05098039, 0.01960784, 0.00784314]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.09019608, 0.04705882, 0.03137255],\n",
       "         [0.07843138, 0.03921569, 0.03137255],\n",
       "         [0.07058824, 0.03137255, 0.02352941]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.09411765, 0.05098039, 0.03529412],\n",
       "         [0.08627451, 0.04705882, 0.03921569],\n",
       "         [0.08235294, 0.04313726, 0.03529412]]]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image.max ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificacion_heridas (x):\n",
    "    print (\"\"\"Probabilidad que sea LPP, Pie diabetico o Ulcera vascular:\"\"\")\n",
    "    return prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "# create a directory to store the model files\n",
    "os.mkdir('tfjs_dir')\n",
    "\n",
    "# convert to Tensorflow.js\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Error\n",
    "# AttributeError: module 'tensorflow.python.data.ops.dataset_ops' \n",
    "    # has no attribute 'UnaryDataset'\n",
    "\n",
    "tfjs.converters.save_keras_model(model, 'tfjs_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classify(model, pak, img, top_n=3):\n",
    "    \"\"\"Classify image and return top matches.\"\"\"\n",
    "    target_size = (224, 224)\n",
    "    if img.size != target_size:\n",
    "        img = img.resize(target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = pak.preprocess_input(x)\n",
    "    preds = heridas_model.predict(x)\n",
    "    return pak.decode_predictions(preds, top=top_n)[0]\n",
    "\n",
    "def plot_preds(img, preds_arr):\n",
    "    \"\"\"Plot image and its prediction.\"\"\"\n",
    "    sns.set_color_codes('pastel')\n",
    "    f, axarr = plt.subplots(1, len(preds_arr) + 1, figsize=(20, 5))\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[0].axis('off')\n",
    "    for i in range(len(preds_arr)):\n",
    "        _, x_label, y_label = zip(*(preds_arr[i][1]))\n",
    "        plt.subplot(1, len(preds_arr) + 1, i + 2)\n",
    "        ax = sns.barplot(np.array(y_label), np.array(x_label))\n",
    "        plt.xlim(0, 1)\n",
    "        ax.set()\n",
    "        plt.xlabel(preds_arr[i][0])\n",
    "    plt.show()\n",
    "    \n",
    "def classify_and_plot(image_path):\n",
    "    \"\"\"Classify an image with model.\n",
    "    Plot it and its predicitons.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    preds_arr = ('model.h5', model)\n",
    "    plot_preds(img, preds_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani",
   "language": "python",
   "name": "dani"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
